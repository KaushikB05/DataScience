{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV , cross_val_score\n",
    "from sklearn.metrics import cohen_kappa_score , make_scorer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA , TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "steel_data = pd.read_csv(\"Faults.NNA\" , sep='\\s+' , header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 34)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steel_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "steel_data.columns# The classes should be randomised but it data it is not randomised . So randomising it \n",
    "# frac = entire data will be choosen but the datpoints will be mixed\n",
    "\n",
    "steel_data_shuffled = steel_data.sample(frac=1.0 , random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The datase has 7 different types of Faults and it has to be put in a single column by argmax func.\n",
    "# Sofirst converting it to array \n",
    "\n",
    "arr = np.array(steel_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32,\n",
       "            33],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steel_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last columns are dummified class information (Faults) - dependent variables\n",
    "# Moving from last\n",
    "# iloc and loc is ONLY for Dataframes \n",
    "# For arrays we can use directly\n",
    "# DataFrame - Different types of datatypes\n",
    "# Array - ONLY one type of datatype\n",
    "\n",
    "X = arr[:,:27] # It will start from 0 column until 26 rows\n",
    "Y = arr[:,27:] # It will start from 28th column(ie 27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941, 7)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting 7 Dimensional data into a single Dimension\n",
    "# Converting dummified column into a single column\n",
    "\n",
    "y = np.argmax(Y, axis=1) # Compare column by column and the column having high value corressponding INDEX will be returned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1941"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1941,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape # We need to supply One dimensional column for SKlearn type of modelling . Fo NN any dimensions can be supplied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Training data =  its fit_transform\n",
    "# For Test data = its ONLY transform \n",
    "# Eg. sc = StandardScaler()\n",
    "#     X_scaled_train = sc.fit_transform(X_train)\n",
    "#     X_scaled_test = sc.fit_transform(X_test) --> WRONG by Logic\n",
    "#     X_scaled_test = sc.transform(X_test)     --> RIGHT\n",
    "\n",
    "X_scaled = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting & XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = GradientBoostingClassifier()  # Loss = Deviance , Learning_rate = 0.1 (constant and not steepest descent)\n",
    "xgb = XGBClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_gbm = GridSearchCV(gbm , param_grid={'learning_rate': [0.01,0.05,0.1],\n",
    "                                          'max_depth':[1,2,3],\n",
    "                                          'n_estimators':[100,200,500] }, cv =5 , n_jobs=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_xgb = GridSearchCV(xgb , param_grid={'learning_rate': [0.01,0.05,0.1],\n",
    "                                          'max_depth':[1,2,3],\n",
    "                                          'n_estimators':[100,200,500] }, cv =5 , n_jobs=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constrai...\n",
       "                                     objective='binary:logistic',\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             iid='warn', n_jobs=1,\n",
       "             param_grid={'learning_rate': [0.01, 0.05, 0.1],\n",
       "                         'max_depth': [1, 2, 3],\n",
       "                         'n_estimators': [100, 200, 500]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_gbm.fit(X_scaled,y)\n",
    "best_xgb.fit(X_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cohen_kappa_score is for imbalance data and multiclass problems\n",
    "\n",
    "def kappa_score(y_actual,y_pred):\n",
    "    return cohen_kappa_score(y_actual,y_pred)\n",
    "\n",
    "Kappa = make_scorer(kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36883177, 0.53820413, 0.54041155, 0.66233697, 0.39831286])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(best_gbm.best_estimator_ , X = X_scaled , y=y , cv=5 , scoring= Kappa , n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.4152731 , 0.55880491, 0.52220041, 0.62620278, 0.45631827])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(best_xgb.best_estimator_ , X = X_scaled , y=y , cv=5 , scoring= Kappa , n_jobs=-1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
